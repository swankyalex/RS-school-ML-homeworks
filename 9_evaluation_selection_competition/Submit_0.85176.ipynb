{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9516425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd12b2",
   "metadata": {},
   "source": [
    "## Prediction 0.85176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1a9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\", index_col=\"Id\")\n",
    "data_test = pd.read_csv(\"test.csv\", index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799db16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELU_CODE = {\n",
    "    1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "    10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "    18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "    26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "    34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "}\n",
    "\n",
    "no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "stony = [6,12]\n",
    "very_stony = [2,9,18,26]\n",
    "extremely_stony = [1,22,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "rubbly = [3,4,5,10,11,13]\n",
    "\n",
    "surface_cover = {i:0 for i in no_desc}\n",
    "surface_cover.update({i:1 for i in stony})\n",
    "surface_cover.update({i:2 for i in very_stony})\n",
    "surface_cover.update({i:3 for i in extremely_stony})\n",
    "surface_cover.update({i:4 for i in rubbly})\n",
    "\n",
    "soil_features = [f'Soil_Type{i}' for i in range(1,41)]\n",
    "wilderness_features = [x for x in data.columns if x.startswith(\"Wilderness_Area\")]\n",
    "\n",
    "def r(x):\n",
    "    if x+180>360:\n",
    "        return x-180\n",
    "    else:\n",
    "        return x+180\n",
    "\n",
    "def misc_features(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    df[\"soil_type_count\"] = df[soil_features].sum(axis=1)\n",
    "    df[\"wilderness_area_count\"] = df[wilderness_features].sum(axis=1)\n",
    "    \n",
    "    df['Soil_Type'] = 0\n",
    "    for i in range(1,41):\n",
    "        df['Soil_Type'] += i*df[f'Soil_Type{i}']\n",
    "        \n",
    "    df['Climatic_Zone'] = df['Soil_Type'].apply(\n",
    "        lambda x: int(str(ELU_CODE[x])[0])\n",
    "    )\n",
    "    \n",
    "    df['Geologic_Zone'] = df['Soil_Type'].apply(\n",
    "        lambda x: int(str(ELU_CODE[x])[1])\n",
    "    )\n",
    "    \n",
    "    df['Surface_Cover'] = df['Soil_Type'].apply(\n",
    "        lambda x: surface_cover[x]\n",
    "    )    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Important Soil Types\n",
    "    df['Soil_12_32'] = df['Soil_Type32'] * df['Soil_Type12']\n",
    "    df['Soil_Type23_22_32_33'] = df['Soil_Type23'] + df['Soil_Type22'] + df['Soil_Type32'] + df['Soil_Type33']\n",
    "    \n",
    "    # Soil Type Interactions\n",
    "    df['Soil29_Area1'] = df['Soil_Type29'] + df['Wilderness_Area1']\n",
    "    df['Soil3_Area4'] = df['Wilderness_Area4'] + df['Soil_Type3']\n",
    "    \n",
    "    #  New Feature Interactions\n",
    "    df['Climate_Area2'] = df['Wilderness_Area2']*df['Climatic_Zone'] \n",
    "    df['Climate_Area4'] = df['Wilderness_Area4']*df['Climatic_Zone']\n",
    "    df['Surface_Area1'] = df['Wilderness_Area1']*df['Surface_Cover'] \n",
    "    df['Surface_Area2'] = df['Wilderness_Area2']*df['Surface_Cover']   \n",
    "    df['Surface_Area4'] = df['Wilderness_Area4']*df['Surface_Cover'] \n",
    "    \n",
    "    \n",
    "    # Use float64 for calculations\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('float'):\n",
    "            df[col] = df[col].astype('float64')\n",
    "            \n",
    "    # Interaction Terms\n",
    "    df['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df['Horizontal_Distance_To_Roadways']]\n",
    "    df['Water Elevation'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n",
    "    df['Hydro_Fire_1'] = df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    df['Hydro_Fire_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n",
    "    df['Hydro_Road_1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Hydro_Road_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])    \n",
    "    df['EVDtH'] = df.Elevation - df.Vertical_Distance_To_Hydrology\n",
    "    df['EHDtH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\n",
    "    df['Elev_3Horiz'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']  + df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Hydrology']\n",
    "    df['Elev_Road_1'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']\n",
    "    df['Elev_Road_2'] = df['Elevation'] - df['Horizontal_Distance_To_Roadways']\n",
    "    df['Elev_Fire_1'] = df['Elevation'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    df['Elev_Fire_2'] = df['Elevation'] - df['Horizontal_Distance_To_Fire_Points']\n",
    "    \n",
    "  \n",
    "    df['EViElv'] = df['Vertical_Distance_To_Hydrology'] * df['Elevation']\n",
    "    df['Aspect2'] = df.Aspect.map(r)\n",
    "\n",
    "    # Fill NA\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    # Downcast variables\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('int'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='integer')\n",
    "        elif dtype.name.startswith('float'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='float')\n",
    "            \n",
    "    df.drop(columns = soil_features, inplace = True)\n",
    "    df.drop(columns = [\"Aspect\"], inplace = True)\n",
    "    df.drop(columns = [\"Horizontal_Distance_To_Roadways\"], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497b9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = misc_features(data)\n",
    "df_test = misc_features(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22da436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_train.columns.to_list()\n",
    "feature_cols.remove(\"Cover_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c370ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_largest_indices(inlist):\n",
    "    largest = 0\n",
    "    second_largest = 0\n",
    "    largest_index = 0\n",
    "    second_largest_index = -1\n",
    "    for i in range(len(inlist)):\n",
    "        item = inlist[i]\n",
    "        if item > largest:\n",
    "            second_largest = largest\n",
    "            second_largest_index = largest_index\n",
    "            largest = item\n",
    "            largest_index = i\n",
    "        elif largest > item >= second_largest:\n",
    "            second_largest = item\n",
    "            second_largest_index = i        \n",
    "    return largest_index, second_largest_index    \n",
    "\n",
    "\n",
    "\n",
    "df_train_1_2 = df_train[(df_train['Cover_Type'] <= 2)]\n",
    "df_train_3_4_6 = df_train[(df_train['Cover_Type'].isin([3,4,6]))]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "\n",
    "X_train_1_2 = df_train_1_2[feature_cols]\n",
    "X_train_3_4_6 = df_train_3_4_6[feature_cols]\n",
    "\n",
    "y = df_train['Cover_Type']\n",
    "y_1_2 = df_train_1_2['Cover_Type']\n",
    "y_3_4_6 = df_train_3_4_6['Cover_Type']\n",
    "\n",
    "test_ids = df_test.index\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=500, random_state=42, max_depth=31, min_samples_split=2, criterion='entropy',\n",
    "                          max_features=12, n_jobs=-1)\n",
    "clf.fit(X_train, y)\n",
    "\n",
    "clf_1_2 = ExtraTreesClassifier(n_estimators=500, random_state=42, max_depth=31, min_samples_split=2, criterion='gini',\n",
    "                          max_features=12, n_jobs=-1)\n",
    "clf_1_2.fit(X_train_1_2, y_1_2)\n",
    "\n",
    "clf_3_4_6 = ExtraTreesClassifier(n_estimators=500, random_state=42, max_depth=31, min_samples_split=2, criterion='gini',\n",
    "                          max_features=12, n_jobs=-1)\n",
    "clf_3_4_6.fit(X_train_3_4_6, y_3_4_6)\n",
    "\n",
    "\n",
    "vals_1_2 = {}\n",
    "for e, val in enumerate(list(clf_1_2.predict_proba(X_test))):\n",
    "    vals_1_2[e] = val\n",
    "\n",
    "\n",
    "vals_3_4_6 = {}\n",
    "for e, val in enumerate(list(clf_3_4_6.predict_proba(X_test))):\n",
    "    vals_3_4_6[e] = val \n",
    "\n",
    "\n",
    "vals = {}\n",
    "for e, val in enumerate(list(clf.predict(X_test))):\n",
    "    vals[e] = val \n",
    "    \n",
    "\n",
    "with open(\"submission.csv\", \"w\") as outfile:\n",
    "    outfile.write(\"Id,Cover_Type\\n\")\n",
    "    for e, val in enumerate(list(clf.predict_proba(X_test))):\n",
    "        val[0] += vals_1_2[e][0]/1.3\n",
    "        val[1] += vals_1_2[e][1]/1.1\n",
    "        val[2] += vals_3_4_6[e][0]/3.4\n",
    "        val[3] += vals_3_4_6[e][1]/4.0\n",
    "        val[5] += vals_3_4_6[e][2]/3.6\n",
    "        i,j = two_largest_indices(val)\n",
    "        v = i  + 1\n",
    "        outfile.write(\"%s,%s\\n\"%(test_ids[e],v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804f59f",
   "metadata": {},
   "source": [
    "![title](https://i.ibb.co/6Fkmbnj/0-85176.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
